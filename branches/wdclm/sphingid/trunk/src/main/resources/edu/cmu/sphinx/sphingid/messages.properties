Sphingid.AddSentenceMarkersShortDescription=Adds sentence markers to each line in the file.
Sphingid.AddSentenceMarkersUsage=Usage: add-sentence-markers input output [encoding]\n\nEncoding property is optional but recommended. You can input an encoding by writing iso-8859-1 or utf-8.
Sphingid.CombineShortDescription=Combines two files.
Sphingid.CombineUsage=Usage: combine input1 input2 ... output
Sphingid.ConfigurationLoadError=Cannot load configuration. Check if the configuration file exists, structure of the file is intact or permissions have been set correctly.
Sphingid.CorrectArgumentsListedBelow=Correct arguments are listed below.\nTry each argument to get more detailed information.
Sphingid.CutoffSegmentsUsage=Specifies number of cutoff segments that the corpus will be separated to. (Default: 5)
Sphingid.CrawlerShortDescription=Reads the configuration file and crawls a list of seed URLs. Multi-threaded. Each crawler only crawls links that are on the same domain.
Sphingid.CrawlUsage=Usage: crawl crawler-configuration
Sphingid.EncodingUsage=Specifies an encoding to use. Examples are iso-8859-1 or utf-8. Defaults to encoding of your system.
Sphingid.IncorrectUsage=Incorrect usage.
Sphingid.InvalidParameter=Invalid parameter: %s
Sphingid.LMDataSelectionShortDescription=Selects sentences from a general corpus that are close to the in-domain data.
Sphingid.LMDataSelectionUsage=Usage: lm-data-selection gigantic-corpus in-domain-corpus [OPTIONS]\n\nSeparates in domain corpus to training and test sets, constructs language models on in-domain corpus and a subset of main corpus, computes sentence-based perplexity differences of the entire corpus using two language models, separates it into n cutoff segments, creates language models for the segments, computes perplexities for the test set, compares it against random selection.\n\nOptions are:
Sphingid.LMDataSelectionWithExistingModelsDescription=Computes sentence-based perplexity differences of the entire corpus using two existing language models, separates it into n cutoff segments, creates language models for the segments, computes perplexities for the test set, compares it against random selection.\n\nThis method is not recommended if you have not constructed the language models with Sphingid. If you must use it, try to use models with constructed with exactly the same parameters.\n\nOptions are:
Sphingid.LMDataSelectionWithExistingModelsShortDescription=Selects sentences from a general corpus that are close to in-domain data, using existing language models created for the corpus and in-domain data.
Sphingid.LMDataSelectionWithExistingModelsUsage=Usage: lm-data-selection-with-existing-models corpus-lm in-domain-lm corpus test-corpus [OPTIONS]\n\n
Sphingid.NUsage=Number of tokens in an n-gram. (Default: 3)
Sphingid.SmoothingUsage=Specifies smoothing setting to use while building a language model with IRST LM. Possible options are witten-bell, kneser-ney, improved-kneser-ney. (Default: improved-kneser-ney)
Sphingid.TestSetPercentageUsage=The amount of corpus that will be used as a test set. (Default: 10)
Sphingid.UseTlmUsage=Uses tlm binary instead of build-lm.sh of IRST LM for constructing language models.
